{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_Unet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZvG6BeCa6laM",
        "colab_type": "code",
        "outputId": "03da3416-7bae-4f60-c4a8-38531b87069d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131304 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--2019-04-10 01:56:04--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
            "Resolving launchpad.net (launchpad.net)... 91.189.89.222, 2001:67c:1560:8003::8004\n",
            "Connecting to launchpad.net (launchpad.net)|91.189.89.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2019-04-10 01:56:04 ERROR 404: Not Found.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb': No such file or directory\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SKiYVezd6z8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4n6HQ8Lx7-27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFqOpxJ88TQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(fold_path):\n",
        "  data = load_files(fold_path)\n",
        "  files = np.array(data['filenames'])\n",
        "  targ = np.array(data['target'])\n",
        "  one_hot = LabelBinarizer()\n",
        "  ohd = one_hot.fit_transform(targ)\n",
        "  return files,ohd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WXlwX6l8X49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ext_im(im_file):\n",
        "  img = cv2.imread(im_file)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(256,256))\n",
        "  img = img/255\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4aL_7Fx8diL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ext_im_gr(im_file):\n",
        "  img = cv2.imread(im_file)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.resize(img,(256,256))\n",
        "  img = np.expand_dims(img,axis=2)\n",
        "  img = img/255\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yuz_93O39RVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tensor_4d(fil):\n",
        "  lis = [ext_im(im) for im in tqdm(fil)]\n",
        "  return np.stack(lis,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGmOATK09YE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tensor_4d_gr(fil):\n",
        "  lis = [ext_im_gr(im) for im in tqdm(fil)]\n",
        "  return np.stack(lis,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bcKU7jS9a52",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_filter(shape,na):\n",
        "  with tf.variable_scope('unet'+na,reuse=tf.AUTO_REUSE):\n",
        "    w = tf.get_variable(name=na,shape=shape,dtype='float32',initializer=tf.random_normal_initializer(dtype='float32',mean=0.0,stddev=1.0))\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFNWcxn39u7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_cof(inp_img,pred_img):\n",
        "  inp = tf.reshape(inp_img,shape=[-1])\n",
        "  pred = tf.reshape(pred_img,shape=[-1])\n",
        "  smooth = 1.0\n",
        "  intersection = tf.reduce_sum(inp*pred)\n",
        "  score = (2.* intersection + smooth)/(tf.reduce_sum(inp) + tf.reduce_sum(pred)+smooth)\n",
        "  return score\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4724Cwk89zhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_loss(inp,pred):\n",
        "  loss = (- dice_cof(inp,pred))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97_8H2j5cifU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def attn_blk(gating_signal,input_signal,old_filters,new_filters,name):\n",
        "  gat_1 = tf.nn.conv2d(gating_signal,filter=get_filter(shape=[1,1,old_filters,new_filters],na=name+'_f1'),stride=[1,1,1,1],padding='SAME',name='ag_'+ name)\n",
        "  gm,gv = tf.nn.moments(gat_1,axes=[0,1,2])\n",
        "  g1 = tf.nn.batch_normalization(gat_1,mean=gm,variance=gv,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ag_bn_'+name)\n",
        "  \n",
        "  ins_1 = tf.nn.conv2d(input_signal,filter=get_filter(shape=[1,1,old_filters,new_filters],na=name+'_x1'),stride=[1,1,1,1],padding='SAME',name='ax_'+ name)\n",
        "  im,iv = tf.nn.moments(ins_1,axes=[0,1,2])\n",
        "  x1 = tf.nn.batch_normalization(ins_1,mean=im,variance=iv,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ax_bn_'+name)\n",
        "  \n",
        "  comb_signal = tf.nn.relu(g1+x1)\n",
        "  \n",
        "  alpha_1 = tf.nn.conv2d(comb_signal,filter=get_filter(shape=[1,1,new_filters,1],na=name+'_alpha1'),stride=[1,1,1,1],padding='SAME',name='alpha_'+ name)\n",
        "  am,av =  tf.nn.moments(alpha_1,axes=[0,1,2])\n",
        "  alpha_2 =  tf.nn.batch_normalization(ins_1,mean=im,variance=iv,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='alpha_bn_'+name)\n",
        "  alpha = tf.nn.sigmoid(alpha_2,name='alpha_final'+name)\n",
        "  return alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVwVUJ6h98Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def attn_unet(inp):\n",
        "  lay_16_1 = tf.nn.conv2d(inp,filter=get_filter(shape=[3,3,3,16],na='w_1'),stride=[1,1,1,1],padding='SAME',name='conv_16_1')\n",
        "  lay_16_2 = tf.nn.relu(lay_16_1,name='re_16_1')\n",
        "  m1,v1 = tf.nn.moments(lay_16_2,axes=[0,1,2])\n",
        "  lay_16_3 = tf.nn.batch_normalization(lay_16_2,mean=m1,variance=v1,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_16')\n",
        "  lay_16_4 = tf.nn.conv2d(lay_16_3,filter=get_filter(shape=[3,3,16,16],na='w_2'),stride=[1,1,1,1],padding='SAME',name='conv_16_2')\n",
        "  lay_16_5 = tf.nn.relu(lay_16_4,name='re_16_2')\n",
        "  lay_p1 = tf.nn.max_pool(lay_16_5)\n",
        "  \n",
        "  lay_32_1 = tf.nn.conv2d(lay_p1,filter=get_filter(shape=[3,3,16,32],na='w_3'),stride=[1,1,1,1],padding='SAME',name='conv_32_1')\n",
        "  lay_32_2 = tf.nn.relu(lay_32_1,name='re_32_1')\n",
        "  m2,v2 = tf.nn.moments(lay_32_2,axes=[0,1,2])\n",
        "  lay_32_3 = tf.nn.batch_normalization(lay_32_2,mean=m2,variance=v2,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_32')\n",
        "  lay_32_4 = tf.nn.conv2d(lay_32_3,filter=get_filter(shape=[3,3,32,32],na='w_4'),stride=[1,1,1,1],padding='SAME',name='conv_32_2')\n",
        "  lay_32_5 = tf.nn.relu(lay_32_4,name='re_32_2')\n",
        "  lay_p2 = tf.nn.max_pool(lay_32_5)\n",
        "  \n",
        "  lay_64_1 = tf.nn.conv2d(lay_p2,filter=get_filter(shape=[3,3,32,64],na='w_5'),stride=[1,1,1,1],padding='SAME',name='conv_64_1')\n",
        "  lay_64_2 = tf.nn.relu(lay_64_1,name='re_64_1')\n",
        "  m3,v3 = tf.nn.moments(lay_64_2,axes=[0,1,2])\n",
        "  lay_64_3 = tf.nn.batch_normalization(lay_64_2,mean=m3,variance=v3,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_64')\n",
        "  lay_64_4 = tf.nn.conv2d(lay_64_3,filter=get_filter(shape=[3,3,64,64],na='w_6'),stride=[1,1,1,1],padding='SAME',name='conv_64_2')\n",
        "  lay_64_5 = tf.nn.relu(lay_64_4,name='re_64_2')\n",
        "  lay_p3 = tf.nn.max_pool(lay_64_5)\n",
        "  \n",
        "  lay_128_1 = tf.nn.conv2d(lay_p3,filter=get_filter(shape=[3,3,64,128],na='w_7'),stride=[1,1,1,1],padding='SAME',name='conv_128_1')\n",
        "  lay_128_2 = tf.nn.relu(lay_128_1,name='re_128_1')\n",
        "  m4,v4 = tf.nn.moments(lay_128_2,axes=[0,1,2])\n",
        "  lay_128_3 = tf.nn.batch_normalization(lay_128_2,mean=m4,variance=v4,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_128')\n",
        "  lay_128_4 = tf.nn.conv2d(lay_128_3,filter=get_filter(shape=[3,3,32,32],na='w_8'),stride=[1,1,1,1],padding='SAME',name='conv_128_2')\n",
        "  lay_128_5 = tf.nn.relu(lay_128_4,name='re_128_2')\n",
        "  lay_p3 = tf.nn.max_pool(lay_128_5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDv55rzP5e1B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}