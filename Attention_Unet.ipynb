{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_Unet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZvG6BeCa6laM",
        "colab_type": "code",
        "outputId": "25c2b381-1626-4601-a1c4-dea084417daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "--2019-04-14 13:03:37--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
            "Resolving launchpad.net (launchpad.net)... 91.189.89.222, 91.189.89.223, 2001:67c:1560:8003::8004, ...\n",
            "Connecting to launchpad.net (launchpad.net)|91.189.89.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2019-04-14 13:03:38 ERROR 404: Not Found.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb': No such file or directory\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SKiYVezd6z8B",
        "colab_type": "code",
        "outputId": "5aab0a4d-619b-4541-e387-370b67f85328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4n6HQ8Lx7-27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFqOpxJ88TQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(fold_path):\n",
        "  data = load_files(fold_path)\n",
        "  files = np.array(data['filenames'])\n",
        "  targ = np.array(data['target'])\n",
        "  one_hot = LabelBinarizer()\n",
        "  ohd = one_hot.fit_transform(targ)\n",
        "  return files,ohd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WXlwX6l8X49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ext_im(im_file):\n",
        "  img = cv2.imread(im_file)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(256,256))\n",
        "  img = img/255\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4aL_7Fx8diL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ext_im_gr(im_file):\n",
        "  img = cv2.imread(im_file)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.resize(img,(256,256))\n",
        "  img = np.expand_dims(img,axis=2)\n",
        "  img = img/255\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yuz_93O39RVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tensor_4d(fil):\n",
        "  lis = [ext_im(im) for im in tqdm(fil)]\n",
        "  return np.stack(lis,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGmOATK09YE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tensor_4d_gr(fil):\n",
        "  lis = [ext_im_gr(im) for im in tqdm(fil)]\n",
        "  return np.stack(lis,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bcKU7jS9a52",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_filter(shape,na):\n",
        "  with tf.variable_scope('unet'+na,reuse=tf.AUTO_REUSE):\n",
        "    w = tf.get_variable(name=na,shape=shape,dtype='float32',initializer=tf.random_normal_initializer(dtype='float32',mean=0.0,stddev=1.0))\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFNWcxn39u7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_cof(inp_img,pred_img):\n",
        "  inp = tf.reshape(inp_img,shape=[-1])\n",
        "  pred = tf.reshape(pred_img,shape=[-1])\n",
        "  smooth = 1.0\n",
        "  intersection = tf.reduce_sum(inp*pred)\n",
        "  score = (2.* intersection + smooth)/(tf.reduce_sum(inp) + tf.reduce_sum(pred)+smooth)\n",
        "  return score\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4724Cwk89zhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_loss(inp,pred):\n",
        "  loss = (- dice_cof(inp,pred))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97_8H2j5cifU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def attn_blk(gating_signal,input_signal,old_filters,new_filters,name):\n",
        "  \n",
        "  gat_1 = tf.nn.conv2d(gating_signal,filter=get_filter(shape=[1,1,old_filters,new_filters],na=name+'_f1'),strides=[1,1,1,1],padding='SAME',name='ag_'+ name)\n",
        "  gm,gv = tf.nn.moments(gat_1,axes=[0,1,2])\n",
        "  g1 = tf.nn.batch_normalization(gat_1,mean=gm,variance=gv,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ag_bn_'+name)\n",
        "  #print('gating',g1.shape)\n",
        "  ins_1 = tf.nn.conv2d(input_signal,filter=get_filter(shape=[1,1,old_filters*2,new_filters],na=name+'_x1'),strides=[1,1,1,1],padding='SAME',name='ax_'+ name)\n",
        "  im,iv = tf.nn.moments(ins_1,axes=[0,1,2])\n",
        "  x1 = tf.nn.batch_normalization(ins_1,mean=im,variance=iv,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ax_bn_'+name)\n",
        "  #print('att',x1.shape)\n",
        "  comb_signal = tf.nn.relu(g1+x1)\n",
        "  #print('comb',comb_signal.shape)\n",
        "  alpha_1 = tf.nn.conv2d(comb_signal,filter=get_filter(shape=[1,1,new_filters,1],na=name+'_alpha1'),strides=[1,1,1,1],padding='SAME',name='alpha_'+ name)\n",
        "  #print('alph',alpha_1.shape)\n",
        "  am,av =  tf.nn.moments(alpha_1,axes=[0,1,2])\n",
        "  alpha_2 =  tf.nn.batch_normalization(alpha_1,mean=am,variance=av,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='alpha_bn_'+name)\n",
        "  alpha = tf.nn.sigmoid(alpha_2,name='alpha_final'+name)\n",
        "  #print('alph',alpha.shape)\n",
        "  return alpha*input_signal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVwVUJ6h98Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def attn_unet(inp):\n",
        "  lay_16_1 = tf.nn.conv2d(inp,filter=get_filter(shape=[3,3,3,16],na='w_1'),strides=[1,1,1,1],padding='SAME',name='conv_16_1')\n",
        "  lay_16_2 = tf.nn.relu(lay_16_1,name='re_16_1')\n",
        "  m1,v1 = tf.nn.moments(lay_16_2,axes=[0,1,2])\n",
        "  lay_16_3 = tf.nn.batch_normalization(lay_16_2,mean=m1,variance=v1,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_16')\n",
        "  lay_16_4 = tf.nn.conv2d(lay_16_3,filter=get_filter(shape=[3,3,16,16],na='w_2'),strides=[1,1,1,1],padding='SAME',name='conv_16_2')\n",
        "  lay_16_5 = tf.nn.relu(lay_16_4,name='re_16_2')\n",
        "  #print(lay_16_5.shape)\n",
        "  lay_p1 = tf.nn.max_pool(lay_16_5,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='pool_1')\n",
        "  ##128 16\n",
        "  lay_32_1 = tf.nn.conv2d(lay_p1,filter=get_filter(shape=[3,3,16,32],na='w_3'),strides=[1,1,1,1],padding='SAME',name='conv_32_1')\n",
        "  lay_32_2 = tf.nn.relu(lay_32_1,name='re_32_1')\n",
        "  m2,v2 = tf.nn.moments(lay_32_2,axes=[0,1,2])\n",
        "  lay_32_3 = tf.nn.batch_normalization(lay_32_2,mean=m2,variance=v2,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_32')\n",
        "  lay_32_4 = tf.nn.conv2d(lay_32_3,filter=get_filter(shape=[3,3,32,32],na='w_4'),strides=[1,1,1,1],padding='SAME',name='conv_32_2')\n",
        "  lay_32_5 = tf.nn.relu(lay_32_4,name='re_32_2')\n",
        "  #print(lay_32_5.shape)\n",
        "  lay_p2 = tf.nn.max_pool(lay_32_5,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='pool_2')\n",
        "  #64 32\n",
        "  lay_64_1 = tf.nn.conv2d(lay_p2,filter=get_filter(shape=[3,3,32,64],na='w_5'),strides=[1,1,1,1],padding='SAME',name='conv_64_1')\n",
        "  lay_64_2 = tf.nn.relu(lay_64_1,name='re_64_1')\n",
        "  m3,v3 = tf.nn.moments(lay_64_2,axes=[0,1,2])\n",
        "  lay_64_3 = tf.nn.batch_normalization(lay_64_2,mean=m3,variance=v3,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_64')\n",
        "  lay_64_4 = tf.nn.conv2d(lay_64_3,filter=get_filter(shape=[3,3,64,64],na='w_6'),strides=[1,1,1,1],padding='SAME',name='conv_64_2')\n",
        "  lay_64_5 = tf.nn.relu(lay_64_4,name='re_64_2')\n",
        "  #print(lay_64_5.shape)\n",
        "  lay_p3 = tf.nn.max_pool(lay_64_5,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='pool_3')\n",
        "  # 32 64\n",
        "  lay_128_1 = tf.nn.conv2d(lay_p3,filter=get_filter(shape=[3,3,64,128],na='w_7'),strides=[1,1,1,1],padding='SAME',name='conv_128_1')\n",
        "  lay_128_2 = tf.nn.relu(lay_128_1,name='re_128_1')\n",
        "  m4,v4 = tf.nn.moments(lay_128_2,axes=[0,1,2])\n",
        "  lay_128_3 = tf.nn.batch_normalization(lay_128_2,mean=m4,variance=v4,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='bn_128')\n",
        "  lay_128_4 = tf.nn.conv2d(lay_128_3,filter=get_filter(shape=[3,3,128,128],na='w_8'),strides=[1,1,1,1],padding='SAME',name='conv_128_2')\n",
        "  lay_128_5 = tf.nn.relu(lay_128_4,name='re_128_2')\n",
        "  #print(lay_128_5.shape)\n",
        "  #lay_p3 = tf.nn.max_pool(lay_128_5)\n",
        "  # 32 128\n",
        "  up_64_1 = tf.image.resize_images(images=lay_128_5,size=[64,64],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  #print(up_64_1.shape)\n",
        "  at_64_2 = attn_blk(lay_64_4,up_64_1,64,32,'attention_1')\n",
        "  #print(at_64_2.shape)\n",
        "  mer_64_3 = tf.concat([lay_64_4,at_64_2],axis=-1,name='merge_1')\n",
        "  #print(mer_64_3.shape)\n",
        "  con_64_4 = tf.nn.conv2d(mer_64_3,filter=get_filter(shape=[3,3,192,64],na='w_9'),strides=[1,1,1,1],padding='SAME',name='up_conv1')\n",
        "  con_64_5 = tf.nn.relu(con_64_4,name='rel_64_1')\n",
        "  m5,v5 = tf.nn.moments(con_64_5,axes=[0,1,2])\n",
        "  con_64_6 = tf.nn.batch_normalization(con_64_5,mean=m5,variance=v5,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ban_64')\n",
        "  con_64_7 = tf.nn.conv2d(con_64_6,filter=get_filter(shape=[3,3,64,64],na='w_10'),strides=[1,1,1,1],padding='SAME',name='up_conv2')\n",
        "  con_64_8 = tf.nn.relu(con_64_7,name='rel_64_2')\n",
        "  \n",
        "  up_32_1 = tf.image.resize_images(images=con_64_8,size=[128,128],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  at_32_2 = attn_blk(lay_32_4,up_32_1,32,16,'attention_2')\n",
        "  mer_32_3 = tf.concat([lay_32_5,at_32_2],axis=-1,name='merge_2')\n",
        "  con_32_4 = tf.nn.conv2d(mer_32_3,filter=get_filter(shape=[3,3,96,32],na='w_11'),strides=[1,1,1,1],padding='SAME',name='up_conv3')\n",
        "  con_32_5 = tf.nn.relu(con_32_4,name='rel_32_1')\n",
        "  m6,v6 = tf.nn.moments(con_32_5,axes=[0,1,2])\n",
        "  con_32_6 = tf.nn.batch_normalization(con_32_5,mean=m6,variance=v6,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ban_32')\n",
        "  con_32_7 = tf.nn.conv2d(con_32_6,filter=get_filter(shape=[3,3,32,32],na='w_12'),strides=[1,1,1,1],padding='SAME',name='up_conv4')\n",
        "  con_32_8 = tf.nn.relu(con_32_7,name='rel_32_2')\n",
        "  \n",
        "  up_16_1 = tf.image.resize_images(images=con_32_8,size=[256,256],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  at_16_2 = attn_blk(lay_16_4,up_16_1,16,8,'attention_3')\n",
        "  mer_16_3 = tf.concat([lay_16_5,at_16_2],axis=-1,name='merge_3')\n",
        "  con_16_4 = tf.nn.conv2d(mer_16_3,filter=get_filter(shape=[3,3,48,16],na='w_13'),strides=[1,1,1,1],padding='SAME',name='up_conv5')\n",
        "  con_16_5 = tf.nn.relu(con_16_4,name='rel_16_1')\n",
        "  m7,v7 = tf.nn.moments(con_16_5,axes=[0,1,2])\n",
        "  con_16_6 = tf.nn.batch_normalization(con_16_5,mean=m7,variance=v7,scale=1.0,offset=0.0,variance_epsilon=0.0003,name='ban_16')\n",
        "  con_16_7 = tf.nn.conv2d(con_16_6,filter=get_filter(shape=[3,3,16,16],na='w_14'),strides=[1,1,1,1],padding='SAME',name='up_conv6')\n",
        "  con_16_8 = tf.nn.relu(con_16_7,name='rel_16_2')\n",
        "  \n",
        "  fin_img = tf.nn.conv2d(con_16_8,filter=get_filter(shape=[3,3,16,1],na='w_15'),strides=[1,1,1,1],padding='SAME',name='final_img')\n",
        "  return fin_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDv55rzP5e1B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_fold = 'drive/datasets/ISBI/images'\n",
        "lab_fold = 'drive/datasets/ISBI/labels'\n",
        "tes_img_fold = 'drive/datasets/ISBI/test/images'\n",
        "tes_lab_fold = 'drive/datasets/ISBI/test/labels'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMFvn03abyvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_files,_ = load_data(img_fold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smCuQWn3b2Rk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lab_files,_ = load_data(lab_fold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4enOTBFb-jU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tes_img_files,_ = load_data(tes_img_fold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YzvxJnx1cp5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tes_lab_files,_ = load_data(tes_lab_fold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_81BFCqdBk6",
        "colab_type": "code",
        "outputId": "a62c253d-672d-4dec-e6df-61f8ed09002f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "imgs = tensor_4d(img_files)\n",
        "tes_imgs = tensor_4d(tes_img_files)\n",
        "labs = tensor_4d_gr(lab_files)\n",
        "tes_labs = tensor_4d_gr(tes_lab_files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 106.14it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 88.07it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 128.04it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 166.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhjmSw2TdTzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ip = tf.placeholder(shape=[None,256,256,3],dtype='float32',name='input_img')\n",
        "op = tf.placeholder(shape=[None,256,256,1],dtype='float32',name='output_img')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3MM43A5dtKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mod = attn_unet(ip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biplCs1zd4Yn",
        "colab_type": "code",
        "outputId": "f7470616-0cf5-4efc-a6b3-f14a21b3c2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "fin_out = tf.nn.sigmoid(mod,name='sigmoid')\n",
        "#los,los_op = tf.metrics.mean_iou(labels=op,predictions=mod,num_classes=1)\n",
        "los = tf.nn.sigmoid_cross_entropy_with_logits(logits=mod,labels=op)\n",
        "los_bce = tf.reduce_mean(los)\n",
        "los_dice = tf.reduce_mean(dice_loss(op,fin_out))\n",
        "los_m = tf.log(los_dice)\n",
        "#los_m = tf.reduce_mean(op * (-tf.log(mod)) + (1 - op) * (-tf.log(1 - mod)),axis=1)\n",
        "#los = tf.reduce_mean(tf.square(mod-op))\n",
        "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "train = opt.minimize(los_m)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yXnLazmV-d4c",
        "colab_type": "code",
        "outputId": "2d96027d-ea29-4b02-ccd6-cb0e23e2ad60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in tqdm(range(80)):\n",
        "    batch = 0\n",
        "    for start,end in zip(range(0,len(imgs),3),range(3,len(imgs),3)):\n",
        "      xtr = imgs[start:end]\n",
        "      ytr = labs[start:end]\n",
        "      #print(xtr.shape)\n",
        "      #x = sess.run(mod,feed_dict={ip:xtr})\n",
        "      #print((los.shape))\n",
        "      sess.run(train,feed_dict={ip:xtr,op:ytr})\n",
        "      lo = sess.run(los_m,feed_dict={ip:xtr,op:ytr})\n",
        "      #print('epoch:',epoch,'batch:',batch,'loss:',lo)\n",
        "      batch = batch + 1\n",
        "    val_loss = sess.run(los_m,feed_dict={ip:tes_imgs,op:tes_labs})\n",
        "    #print('epoch:',epoch,'val loss:',val_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [02:09<00:00,  1.61s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5hhyf4LR-xoR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}